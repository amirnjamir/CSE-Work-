{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3927af01-7502-499a-8d56-f0dad6df827e",
   "metadata": {},
   "source": [
    "Programming Excercises - Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4adc87d9-9eaa-452a-9a5c-897715084128",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "if you give only one argument to maketrans it must be a dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Remove punctuation and convert text to lowercase\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring.punctuation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mtranslate(translator)\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Store unique words in a set\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: if you give only one argument to maketrans it must be a dict"
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "#Function to read and process the text file \n",
    "def get_unique_words(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"The file does not exist.\"\n",
    "\n",
    "#Remove punctuation and convert text to lowercase\n",
    "translator = str.maketrans(\"string.punctuation\")\n",
    "text = text.translate(translator).lower()\n",
    "\n",
    "#Store unique words in a set\n",
    "unique_words = set(words)\n",
    "\n",
    "return unique_words\n",
    "\n",
    "#Specify the file Path\n",
    "file_path = 'sample_text_for_assignment' # Ensure this is the correct path \n",
    "\n",
    "#Get unique words from the specified file\n",
    "unique_words = get_unique_words(file_path)\n",
    "\n",
    "#Display the unique words \n",
    "if isinstance(unique_words, str):\n",
    "    print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f6999-1314-40a8-846a-9f9b214f692d",
   "metadata": {},
   "source": [
    "At first I thought it was a little gramatical error, but clearly not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7e5b32-d489-4e01-889c-c1e77520302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words found in the file:\n",
      "extraction\n",
      "set\n",
      "is\n",
      "a\n",
      "text\n",
      "some\n",
      "file\n",
      "to\n",
      "unique\n",
      "demonstrate\n",
      "words\n",
      "the\n",
      "sample\n",
      "contains\n",
      "in\n",
      "this\n",
      "stored\n",
      "are\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "#Function to read and process the text file \n",
    "def get_unique_words(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"The file does not exist.\"\n",
    "\n",
    "    #Remove punctuation and convert text to lowercase\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator).lower()\n",
    "\n",
    "    #Split text into words\n",
    "    words = text.split()\n",
    "\n",
    "    #Store unique words in a set\n",
    "    unique_words = set(words)\n",
    "\n",
    "    return unique_words\n",
    "\n",
    "#Specify the file Path\n",
    "file_path = 'sample_text_for_assignment.txt' # Ensure this is the correct path \n",
    "\n",
    "#Get unique words from the specified file\n",
    "unique_words = get_unique_words(file_path)\n",
    "\n",
    "#Display the unique words \n",
    "if isinstance(unique_words, str):\n",
    "    print(unique_words)\n",
    "else:\n",
    "    print(\"Unique words found in the file:\")\n",
    "    for word in unique_words:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e736f84-e3bb-403f-b20a-4c4301d52f2c",
   "metadata": {},
   "source": [
    "It has something do with the indents, I think."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d58e0ef-38f2-49bb-82ec-178f51db053b",
   "metadata": {},
   "source": [
    "My thought process was a little thrown off mainly by the little things like indenting and some grammatical errors for the functions. Nonetheless heres, more or less how I got it. Read the file previously created, then process its context to remove punctuation and convert it to lowercase, split the text into individual words. Additioanlly, store and display only the unique words. Going a little bit more in depth, the string module provides a collection of string operations. Then the function 'get_unique_words' is made to get logic for reading and processing the file. The try block is meant to handle possible errors we encounter while were trying to open this file. For reference, str.maketrans('', '', string.punctuation): creates a translation table that maps each punctuation character to None. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4130cc-d455-4a9d-876e-506715bd39d2",
   "metadata": {},
   "source": [
    "Furthermrore, we use text.lower() to make the letters lowercas. The split() splits the 'text' into words based on the given whitespace. It then takes the list of words and turns it intoi a set() and later asks to return the uniqwue words found. Lastly, all you do is call the function and the code should display the results like it did above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950168f3-cdc0-4c95-bae7-357d2b1e3356",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
